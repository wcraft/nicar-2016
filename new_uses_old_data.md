New Uses for Old Data
=====================
John Perry, Atlanta Journal-Cobstitution
Chase Davis, NY Times
Ryan McNeill, Reuters

# Testing the Tests
Looking at test score data with a more skeptical eye, most test score data is crap

## Test security
Presenter looked at cheating within the schools. A way of looking at the
* do teachers proctor tests for their own classes?
  * motivation for helping your students along, the teachers have jobs and pay based on the results of these tests
  * there are subtle ways of cheating, like leaving posters on the wall with answers
* Are there test monitors, are there people poking around during the test to make sure there is no cheating
* do the tests sit around at schools without security before the test?
* Does the state do stats analysis that looks for cheating

## Are the tests valid?
* Who develops the questions? Are they reviewed by teachers and experts beforehand
* testing the tests
* p-value, look at percent right and wrong
  * maybe that means a bad question
* discrimination
  * are kids who score higher more likely to get a certain question right
* differential
  * is there cultural biases on questions
* scoring errors
  * how common is it that the tests themselves are wrong
* These are all things that the dept. of education should be doing! go after the data

## tests as teacher evaluation tools
* these stats models that take out factors other than teaching, district hiring outside experts
  * who is being hired, are their research methods valid?
* results, do the results correlate with race and poverty

# Election Data
Chase Davis, NYT, runs interactive desk
New way of looking at/dealing with election data
The interactive works with the CAR team on campaign finance, sifts through the data, works with the viz desk to build out the visualizations
* uses the elections to test new ideas, doing a lot of new work with regards to the data that is being made
  * talk will be about boring stuff, the actual results. This panel is about coming up with new approaches to things that come up all the time
* ability to change what they do around elections is limited to the one thing they need to convey: who is winning
* evolution over the way NYT deals with election results, the surface doesn't look like a huge change, but there has been
  * a large portion of the change has been their process, innovation within the constraint of the data
  * how to improve process, how to improve the behind-the-scenes
* built internal tools to help spread the work of taking in results data and getting it to the people that need it
  * elex is part of that
* the tech changes and the internal innovation has allowed for a better experience for the reader, can push updates live, has allowed for people who are not the devs to push out changes slash pull data

## Same as it ever was?
Ryan McNeill, Reuters
How to use long-existing data to tell a new story, looking at sea level rise
investigation: Water's Edge

* The problem: what is happening now?
* data comes from noaa tides adn currents
  * historic tide gauge data
* there are other uses for tide data
  * tide gauges can have far more data than just water levels
* you can automate the data download from the tides and currents NOAA api
* has flooding thresholds for a lot of different places
* had hourly tide gauge readings and flood thresholds
* Looked at days at or exceeding flood level, starting at 1920
  * how many days had water exceeding flood levels
    * visualized, you can see clear rise in the frequency of flood days
* looked at longterm sealevel rise  by taking monthly average
* created a great visual timeline of water crossing flood threshold
  * graphed floods per station
